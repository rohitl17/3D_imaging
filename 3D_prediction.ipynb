{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from tqdm.notebook import tqdm\n",
    "from statistics import mean \n",
    "\n",
    "from natsort import natsorted\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.utils import Sequence\n",
    "import math\n",
    "import pydicom\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ImageSliceViewer3DMultipleColour:\n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
    "    ipython notebooks. \n",
    "    \n",
    "    User can interactively change the slice plane selection for the image and \n",
    "    the slice plane being viewed. \n",
    "\n",
    "    Argumentss:\n",
    "    Volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('plasma'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, volume, volume_1, volume_2, figsize=(8,8), cmap='plasma'):\n",
    "        self.volume = volume/np.max(volume)\n",
    "        self.volume_1 = volume_1/np.max(volume_1)\n",
    "        self.volume_2 = volume_2/np.max(volume_2)\n",
    "        self.figsize = figsize\n",
    "        self.cmap = cmap\n",
    "        self.v = [np.min(volume), np.max(volume)]\n",
    "        \n",
    "        # Call to select slice plane\n",
    "        ipyw.interact(self.view_selection, view=ipyw.RadioButtons(\n",
    "            options=['x-y','y-z', 'z-x'], value='x-y', \n",
    "            description='Slice plane selection:', disabled=False,\n",
    "            style={'description_width': 'initial'}))\n",
    "    \n",
    "    def view_selection(self, view):\n",
    "        # Transpose the volume to orient according to the slice plane selection\n",
    "        orient = {\"y-z\":[1,2,0], \"z-x\":[2,0,1], \"x-y\": [0,1,2]}\n",
    "        self.vol = np.transpose(self.volume, orient[view])\n",
    "        self.vol_1 = np.transpose(self.volume_1, orient[view])\n",
    "        self.vol_2 = np.transpose(self.volume_2, orient[view])\n",
    "        maxZ = self.vol.shape[2] - 1\n",
    "        \n",
    "        # Call to view a slice within the selected slice plane\n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z=ipyw.IntSlider(min=0, max=maxZ, step=1, continuous_update=False, \n",
    "            description='Image Slice:'))\n",
    "        \n",
    "    def plot_slice(self, z):\n",
    "        # Plot slice for the given plane and slice\n",
    "        self.fig = plt.figure(figsize=self.figsize)\n",
    "        \n",
    "        img_true_mask = cv2.addWeighted(self.vol_1[:,:,z], 0.7, self.vol[:,:,z], 1, 0)\n",
    "        img_pred_mask = cv2.addWeighted(self.vol_2[:,:,z], 0.7, self.vol[:,:,z], 1, 0)\n",
    "#         final_image = np.hstack([self.vol[:,:,z], self.vol_1[:,:,z], self.vol_2[:,:,z]])\n",
    "        final_image = np.hstack([self.vol[:,:,z], img_true_mask, img_pred_mask])\n",
    "        self.ct_slice = self.vol[:,:,z]\n",
    "        self.final_image = final_image\n",
    "        self.img_true_mask = img_true_mask\n",
    "        self.img_pred_mask = img_pred_mask\n",
    "        self.z = z\n",
    "        plt.imshow(final_image, cmap=plt.get_cmap(self.cmap))\n",
    "#         return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMaxLength(arr):\n",
    " \n",
    "    # intitialize count\n",
    "    count = 0\n",
    "     \n",
    "    # initialize max\n",
    "    result = 0\n",
    " \n",
    "    for i in range(0, len(arr)):\n",
    "     \n",
    "        # Reset count when 0 is found\n",
    "        if (arr[i] == 0):\n",
    "            count = 0\n",
    " \n",
    "        # If 1 is found, increment count\n",
    "        # and update result if count  \n",
    "        # becomes more.\n",
    "        else:\n",
    "             \n",
    "            # increase count\n",
    "            count+= 1\n",
    "            result = max(result, count)  \n",
    "         \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ImageSliceViewer3D:\n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
    "    ipython notebooks. \n",
    "    \n",
    "    User can interactively change the slice plane selection for the image and \n",
    "    the slice plane being viewed. \n",
    "\n",
    "    Argumentss:\n",
    "    Volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('plasma'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, volume, figsize=(8,8), cmap='plasma'):\n",
    "        self.volume = volume\n",
    "        self.figsize = figsize\n",
    "        self.cmap = cmap\n",
    "        self.v = [np.min(volume), np.max(volume)]\n",
    "        \n",
    "        # Call to select slice plane\n",
    "        ipyw.interact(self.view_selection, view=ipyw.RadioButtons(\n",
    "            options=['x-y','y-z', 'z-x'], value='x-y', \n",
    "            description='Slice plane selection:', disabled=False,\n",
    "            style={'description_width': 'initial'}))\n",
    "    \n",
    "    def view_selection(self, view):\n",
    "        # Transpose the volume to orient according to the slice plane selection\n",
    "        orient = {\"y-z\":[1,2,0], \"z-x\":[2,0,1], \"x-y\": [0,1,2]}\n",
    "        self.vol = np.transpose(self.volume, orient[view])\n",
    "        maxZ = self.vol.shape[2] - 1\n",
    "        \n",
    "        # Call to view a slice within the selected slice plane\n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z=ipyw.IntSlider(min=0, max=maxZ, step=1, continuous_update=False, \n",
    "            description='Image Slice:'))\n",
    "        \n",
    "    def plot_slice(self, z):\n",
    "        # Plot slice for the given plane and slice\n",
    "        self.fig = plt.figure(figsize=self.figsize)\n",
    "        plt.imshow(self.vol[:,:,z], cmap=plt.get_cmap(self.cmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as ipyw\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class ImageSliceViewer3DMultiple:\n",
    "    \"\"\" \n",
    "    ImageSliceViewer3D is for viewing volumetric image slices in jupyter or\n",
    "    ipython notebooks. \n",
    "    \n",
    "    User can interactively change the slice plane selection for the image and \n",
    "    the slice plane being viewed. \n",
    "\n",
    "    Argumentss:\n",
    "    Volume = 3D input image\n",
    "    figsize = default(8,8), to set the size of the figure\n",
    "    cmap = default('plasma'), string for the matplotlib colormap. You can find \n",
    "    more matplotlib colormaps on the following link:\n",
    "    https://matplotlib.org/users/colormaps.html\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, volume, volume_1, volume_2, figsize=(8,8), cmap='plasma'):\n",
    "        self.volume = volume/np.max(volume)\n",
    "        self.volume_1 = volume_1/np.max(volume_1)\n",
    "        self.volume_2 = volume_2/np.max(volume_2)\n",
    "        self.figsize = figsize\n",
    "        self.cmap = cmap\n",
    "        self.v = [np.min(volume), np.max(volume)]\n",
    "        \n",
    "        # Call to select slice plane\n",
    "        ipyw.interact(self.view_selection, view=ipyw.RadioButtons(\n",
    "            options=['x-y','y-z', 'z-x'], value='x-y', \n",
    "            description='Slice plane selection:', disabled=False,\n",
    "            style={'description_width': 'initial'}))\n",
    "    \n",
    "    def view_selection(self, view):\n",
    "        # Transpose the volume to orient according to the slice plane selection\n",
    "        orient = {\"y-z\":[1,2,0], \"z-x\":[2,0,1], \"x-y\": [0,1,2]}\n",
    "        self.vol = np.transpose(self.volume, orient[view])\n",
    "        self.vol_1 = np.transpose(self.volume_1, orient[view])\n",
    "        self.vol_2 = np.transpose(self.volume_2, orient[view])\n",
    "        maxZ = self.vol.shape[2] - 1\n",
    "        \n",
    "        # Call to view a slice within the selected slice plane\n",
    "        ipyw.interact(self.plot_slice, \n",
    "            z=ipyw.IntSlider(min=0, max=maxZ, step=1, continuous_update=False, \n",
    "            description='Image Slice:'))\n",
    "        \n",
    "    def plot_slice(self, z):\n",
    "        # Plot slice for the given plane and slice\n",
    "        self.fig = plt.figure(figsize=self.figsize)\n",
    "        \n",
    "        final_image = np.hstack([self.vol[:,:,z], self.vol_1[:,:,z], self.vol_2[:,:,z]])\n",
    "        \n",
    "        plt.imshow(final_image, cmap=plt.get_cmap(self.cmap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "V-Net Architecture\n",
    "\"\"\"\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "# import keras.layers as keras_contrib \n",
    "import keras_contrib\n",
    "# import tensorflow_addons as keras_contrib\n",
    "# tfa\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Building blocks\n",
    "def adding_conv(x, a, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    channel_axis = -1 if data_format=='channels_last' else 1\n",
    "    c = keras.layers.Conv3D(filters, kernel_size, padding=padding, strides=strides, \n",
    "            activation=None, data_format=data_format)(x)\n",
    "    c = keras.layers.add([c, a])\n",
    "    c = keras_contrib.layers.GroupNormalization(groups=groups, axis=channel_axis)(c)\n",
    "    c = keras.layers.advanced_activations.PReLU()(c)\n",
    "    return c\n",
    "\n",
    "def conv(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    channel_axis = -1 if data_format=='channels_last' else 1\n",
    "    c = keras.layers.Conv3D(filters, kernel_size, padding=padding, strides=strides, \n",
    "            activation=None, data_format=data_format)(x)\n",
    "    c = keras_contrib.layers.GroupNormalization(groups=groups, axis=channel_axis)(c)\n",
    "    c = keras.layers.advanced_activations.PReLU()(c)\n",
    "    return c\n",
    "\n",
    "def down_conv(x, filters, kernel_size, padding, data_format, groups):\n",
    "    channel_axis = -1 if data_format=='channels_last' else 1\n",
    "    c = keras.layers.Conv3D(filters, kernel_size, padding=padding, strides=2, \n",
    "                            activation=None, data_format=data_format)(x)\n",
    "    c = keras_contrib.layers.GroupNormalization(groups=groups, axis=channel_axis)(c)\n",
    "    c = keras.layers.advanced_activations.PReLU()(c)\n",
    "    return c\n",
    "\n",
    "def up_conv_concat_conv(x, skip, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    channel_axis = -1 if data_format=='channels_last' else 1\n",
    "    c = keras.layers.Conv3DTranspose(filters, kernel_size=(2,2,2), strides=(2,2,2), \n",
    "                                    data_format=data_format)(x) # up dim(x) by x2\n",
    "    c = keras_contrib.layers.GroupNormalization(groups=groups, axis=channel_axis)(c)\n",
    "    c = keras.layers.Conv3D(filters, kernel_size, padding=padding, strides=strides, \n",
    "                            activation=None, data_format=data_format)(c)\n",
    "    concat = keras.layers.Concatenate(axis=channel_axis)([c, skip]) # concat after Up; dim(skip) == 2*dim(x)\n",
    "    c = keras_contrib.layers.GroupNormalization(groups=groups, axis=channel_axis)(concat)\n",
    "    c = keras.layers.advanced_activations.PReLU()(c)\n",
    "    return c\n",
    "\n",
    "\n",
    "# Encoders\n",
    "def encoder1(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('encoder1'):\n",
    "        with tf.variable_scope('conv'):\n",
    "            conv1 = conv(x, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        with tf.variable_scope('addconv'):\n",
    "            addconv = adding_conv(conv1, conv1, filters, kernel_size, padding, strides, data_format, groups) # N\n",
    "        with tf.variable_scope('downconv'):\n",
    "            downconv = down_conv(addconv, filters*2, kernel_size, padding, data_format, groups) # N/2\n",
    "        return (addconv, downconv)\n",
    "\n",
    "def encoder2(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('encoder2'):\n",
    "        with tf.variable_scope('conv'):\n",
    "            conv1 = conv(x, filters, kernel_size, padding, strides, data_format, groups) \n",
    "        with tf.variable_scope('addconv'):\n",
    "            addconv = adding_conv(conv1, x, filters, kernel_size, padding, strides, data_format, groups) # N/2\n",
    "        with tf.variable_scope('downconv'):\n",
    "            downconv = down_conv(addconv, filters*2, kernel_size, padding, data_format, groups) # N/4\n",
    "        return (addconv, downconv)\n",
    "\n",
    "def encoder3(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('encoder3'):\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = conv(x, filters, kernel_size, padding, strides, data_format, groups) # N/4\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = conv(conv1, filters, kernel_size, padding, strides, data_format, groups) # N/4\n",
    "        with tf.variable_scope('addconv'):\n",
    "            addconv = adding_conv(conv2, x, filters, kernel_size, padding, strides, data_format, groups) # N/4\n",
    "        with tf.variable_scope('downconv'):\n",
    "            downconv = down_conv(addconv, filters*2, kernel_size, padding, data_format, groups) # N/8\n",
    "        return (addconv, downconv)\n",
    "\n",
    "def encoder4(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('encoder4'):\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = conv(x, filters, kernel_size, padding, strides, data_format, groups) # N/8\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = conv(conv1, filters, kernel_size, padding, strides, data_format, groups) # N/8\n",
    "        with tf.variable_scope('addconv'):\n",
    "            addconv = adding_conv(conv2, x, filters, kernel_size, padding, strides, data_format, groups) # N/8\n",
    "        with tf.variable_scope('downconv'):\n",
    "            downconv = down_conv(addconv, filters*2, kernel_size, padding, data_format, groups) # N/16\n",
    "        return (addconv, downconv)\n",
    "\n",
    "\n",
    "# Bottom\n",
    "def bottom(x, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('bottom'):\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = conv(x, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = conv(conv1, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        with tf.variable_scope('addconv'):\n",
    "            addconv = adding_conv(conv2, x, filters, kernel_size, padding, strides, data_format, groups) # N/16\n",
    "        return addconv # N/16\n",
    "\n",
    "\n",
    "# Decoders\n",
    "def decoder4(x, skip, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('decoder4'):\n",
    "        with tf.variable_scope('upconv'):\n",
    "            upconv = up_conv_concat_conv(x, skip, filters, kernel_size, padding, strides, data_format, groups) # N/8\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = conv(upconv, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = conv(conv1, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        return conv2 # N/8\n",
    "\n",
    "def decoder3(x, skip, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('decoder3'):\n",
    "        with tf.variable_scope('upconv'):\n",
    "            upconv = up_conv_concat_conv(x, skip, filters, kernel_size, padding, strides, data_format, groups) # N/4\n",
    "        with tf.variable_scope('conv1'):\n",
    "            conv1 = conv(upconv, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        with tf.variable_scope('conv2'):\n",
    "            conv2 = conv(conv1, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        return conv2 # N/4\n",
    "\n",
    "def decoder2(x, skip, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('decoder2'):\n",
    "        with tf.variable_scope('upconv'):\n",
    "            upconv = up_conv_concat_conv(x, skip, filters, kernel_size, padding, strides, data_format, groups) # N/2\n",
    "        with tf.variable_scope('conv'):\n",
    "            conv1 = conv(upconv, filters, kernel_size, padding, strides, data_format, groups)\n",
    "        return conv1 # N/2\n",
    "\n",
    "def decoder1(x, skip, filters, kernel_size, padding, strides, data_format, groups):\n",
    "    with tf.variable_scope('decoder1'):\n",
    "        with tf.variable_scope('upconv'):\n",
    "            upconv = up_conv_concat_conv(x, skip, filters, kernel_size, padding, strides, data_format, groups) # N\n",
    "        return upconv # N\n",
    "\n",
    "\n",
    "# Attention gate\n",
    "def attention_gate(inp, g, intra_filters):\n",
    "    with tf.variable_scope('attention_gate'):\n",
    "        data_format = 'channels_first'##@##\n",
    "        groups = 8 ##@##\n",
    "\n",
    "        # Gating signal processing\n",
    "        g = keras.layers.Conv3D(intra_filters, kernel_size=1, data_format=data_format)(g) # N/2\n",
    "        g = keras_contrib.layers.GroupNormalization(groups=groups, axis=1)(g) # N/2\n",
    "\n",
    "        # Skip signal processing: \n",
    "        x = keras.layers.Conv3D(intra_filters, kernel_size=2, strides=2, padding='same', data_format=data_format)(inp) # N-->N/2\n",
    "        x = keras_contrib.layers.GroupNormalization(groups=groups, axis=1)(x) # N\n",
    "\n",
    "        # Add and proc\n",
    "        g_x = keras.layers.Add()([g, x]) # N/2\n",
    "        psi = keras.layers.Activation('relu')(g_x) # N/2\n",
    "        psi = keras.layers.Conv3D(1, kernel_size = 1, padding='same', data_format=data_format)(psi) # N/2\n",
    "        psi = keras_contrib.layers.GroupNormalization(groups=1, axis=1)(psi) # N/2\n",
    "        psi = keras.layers.Activation('sigmoid')(psi) # N/2\n",
    "        alpha = keras.layers.UpSampling3D(size=2, data_format=data_format)(psi) # N/2-->N\n",
    "\n",
    "\n",
    "        x_hat = keras.layers.Multiply()([inp, alpha])\n",
    "        return x_hat\n",
    "\n",
    "\n",
    "# Model\n",
    "def VNet(n_in, n_out, image_shape, filters, kernel_size, padding, strides, data_format, groups, inter_filters):\n",
    "    with tf.variable_scope('VNet'):\n",
    "        input_dim = image_shape+(n_in,) if data_format=='channels_last' \\\n",
    "            else (n_in,)+image_shape\n",
    "        \n",
    "        inputs = keras.layers.Input(input_dim)\n",
    "\n",
    "        (encoder1_addconv, encoder1_downconv) = encoder1(inputs, filters*2**0, kernel_size, padding, strides, data_format, groups) # N, N/2\n",
    "        (encoder2_addconv, encoder2_downconv) = encoder2(encoder1_downconv, filters*2**1, kernel_size, padding, strides, data_format, groups) # N/2, N/4\n",
    "        (encoder3_addconv, encoder3_downconv) = encoder3(encoder2_downconv, filters*2**2, kernel_size, padding, strides, data_format, groups) # N/4, N/8\n",
    "        (encoder4_addconv, encoder4_downconv) = encoder4(encoder3_downconv, filters*2**3, kernel_size, padding, strides, data_format, groups) # N/8, N/16\n",
    "\n",
    "        bottom_addconv = bottom(encoder4_downconv, filters*2**4, kernel_size, padding, strides, data_format, groups) # N/16\n",
    "\n",
    "        encoder4_ag = attention_gate(encoder4_addconv, bottom_addconv, inter_filters) # (N/8, N/16) --> N/8\n",
    "        decoder4_conv = decoder4(bottom_addconv, encoder4_ag, filters*2**3, kernel_size, padding, strides, data_format, groups) # N/8\n",
    "        encoder3_ag = attention_gate(encoder3_addconv, decoder4_conv, inter_filters) # (N/4, N/8) --> N/4\n",
    "        decoder3_conv = decoder3(decoder4_conv, encoder3_ag, filters*2**2, kernel_size, padding, strides, data_format, groups) # N/4\n",
    "        encoder2_ag = attention_gate(encoder2_addconv, decoder3_conv, inter_filters) # (N/2, N/4) --> N/2\n",
    "        decoder2_conv = decoder2(decoder3_conv, encoder2_ag, filters*2**1, kernel_size, padding, strides, data_format, groups) # N/2\n",
    "        encoder1_ag = attention_gate(encoder1_addconv, decoder2_conv, inter_filters) # (N, N/2) --> N\n",
    "        decoder1_conv = decoder1(decoder2_conv, encoder1_ag, filters*2**0, kernel_size, padding, strides, data_format, groups) # N\n",
    "       \n",
    "        with tf.variable_scope(\"output\"):\n",
    "            outputs = keras.layers.Conv3D(n_out,\n",
    "                (1,1,1),\n",
    "                padding='same',\n",
    "                activation='sigmoid',\n",
    "                data_format=data_format)(decoder1_conv)\n",
    "\n",
    "            model = keras.models.Model(inputs, outputs)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Generator for 3D Model\n",
    "\"\"\"\n",
    "\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import random\n",
    "class VolDataGenerator3D(Sequence):\n",
    "    \n",
    "    def __init__(self, ct_dataframe, unique_id_list, list_num_slices_list, batch_size, image_size, stack_size, overlap_size):\n",
    "        self.unique_id_list = unique_id_list\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.ct_dataframe = ct_dataframe\n",
    "        self.stack_size = stack_size\n",
    "        self.overlap_size = overlap_size\n",
    "        self.batch_size = batch_size\n",
    "        self.list_num_slices_list = list_num_slices_list\n",
    "        \n",
    "        assert(self.overlap_size < self.stack_size)\n",
    "        random.seed(7)\n",
    "        self.list_of_stacks = [(self.unique_id_list[i], current_stack) for i in range(len(self.unique_id_list)) for current_stack in self.make_overlapping_stacks(self.list_num_slices_list[i], self.stack_size, self.overlap_size) ]\n",
    "#         random.shuffle(self.list_of_stacks)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(math.ceil(len(self.list_of_stacks)/self.batch_size))\n",
    "\n",
    "    \n",
    "    def rle_decode(self, mask_rle, shape):\n",
    "        \"\"\"\n",
    "        Return an image array from run-length encoded string `mask_rle` with `shape`.\n",
    "        \"\"\"\n",
    "        img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n",
    "        if mask_rle==[]:\n",
    "            return np.zeros((shape[0], shape[1]), dtype=np.uint)\n",
    "        else:\n",
    "            s = mask_rle[0].split()\n",
    "            starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "            starts -= 1\n",
    "            ends = starts + lengths\n",
    "\n",
    "            for low, up in zip(starts, ends): img[low:up] = 1\n",
    "        return img.reshape(shape)\n",
    "\n",
    "        \n",
    "    def make_overlapping_stacks(self, num_slices, stack_size, overlap_size):\n",
    "        list_of_indices = [(start, min(start + stack_size, num_slices - 1)) for start in range(0, num_slices, stack_size - overlap_size)]\n",
    "        all_endings = list(map(lambda x: x[1], list_of_indices))\n",
    "        first_index_of_max_end = all_endings.index(max(all_endings))\n",
    "        list_of_indices = list_of_indices[: first_index_of_max_end + 1]\n",
    "        self.list_of_indices = list_of_indices\n",
    "        return list_of_indices\n",
    "\n",
    "\n",
    "    def create_3d_vol(self, name_vs_num_slices_element):\n",
    "#         name_vs_num_slices_element = ('img_0', (0, 100))\n",
    "        self.name_vs_num_slices_element = name_vs_num_slices_element\n",
    "        temp_df = self.ct_dataframe.loc[self.ct_dataframe[\"unique_identifier\"] == name_vs_num_slices_element[0]]\n",
    "        temp_df = temp_df.iloc[name_vs_num_slices_element[1][0] : name_vs_num_slices_element[1][1]]\n",
    "        temp_df = temp_df.reset_index(drop=True)\n",
    "        \n",
    "        img_size = (pydicom.read_file(temp_df.iloc[0].dicom_path).pixel_array).shape  #SHAPE OF IMAGE\n",
    "        \n",
    "        img_vol = np.zeros((self.image_size[0], self.image_size[1],  self.stack_size))\n",
    "        label_vol = np.zeros((self.image_size[0], self.image_size[1],  self.stack_size))\n",
    "        \n",
    "#         sum_pathos = 0\n",
    "#         sum_pathos = temp_df.combine_pathos.sum()\n",
    "        \n",
    "        for i, row in temp_df.iterrows():\n",
    "            img = (pydicom.read_file(row.dicom_path).pixel_array)\n",
    "            img = cv2.resize(img, (self.image_size[0], self.image_size[1]))\n",
    "            img_vol[:,:,i] = img\n",
    "            \n",
    "        unique_unique = (temp_df.combine_pathos.unique()).all()\n",
    "        \n",
    "#         if unique_unique != '[]':      #FOR OUTER CLASS TEST CSV\n",
    "            \n",
    "        for i, row in temp_df.iterrows():\n",
    "\n",
    "            label_con = np.maximum(self.rle_decode(eval(row.consolidation), img_size), self.rle_decode(eval(row.predominant_consolidation), img_size))\n",
    "            label_ggo = np.maximum(self.rle_decode(eval(row.ground_glass_opacity), img_size), self.rle_decode(eval(row.predominant_ground_glass_opacity), img_size))\n",
    "            label_whole = np.maximum(label_con, label_ggo)\n",
    "            label = cv2.resize(label_whole.astype(float), (self.image_size[0], self.image_size[1]))\n",
    "            label_vol[:,:,i] = label\n",
    "                \n",
    "        self.temp_df = temp_df\n",
    "        return img_vol, label_vol\n",
    "            \n",
    "\n",
    "    def create_volume_image(self, name_vs_num_slices_element):\n",
    "        img_vol, label_vol = self.create_3d_vol(name_vs_num_slices_element)        \n",
    "        \n",
    "        img_vol = np.expand_dims(img_vol, 0)\n",
    "        label_vol = np.expand_dims(label_vol, 0)\n",
    "        return img_vol, label_vol\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        studies_for_this_batch = self.list_of_stacks[(self.batch_size*index):self.batch_size*(index+1)]\n",
    "        self.studies_for_this_batch = studies_for_this_batch\n",
    "        \n",
    "        X = np.zeros((len(studies_for_this_batch), 1, self.image_size[0], self.image_size[1], self.stack_size))\n",
    "        Y = np.zeros((len(studies_for_this_batch), 1, self.image_size[0], self.image_size[1], self.stack_size))\n",
    "        \n",
    "   \n",
    "        for j,study in enumerate(studies_for_this_batch):\n",
    "            X[j], Y[j] = self.create_volume_image(study)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finds Number of slices give the ID\n",
    "\"\"\"\n",
    "\n",
    "def find_num_slices_list(dataframe, scan_name_list):\n",
    "    num_slices_list = []\n",
    "    for name in scan_name_list:\n",
    "        temp_df = dataframe.loc[dataframe.unique_identifier==name]\n",
    "        num_slices_list.append(len(temp_df))\n",
    "    return num_slices_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the final CSV Made using the same procedure while training\n",
    "\"\"\"\n",
    "final_test_df_unique_series_id_list = (final_test_df.unique_identifier.unique())\n",
    "final_test_df_unique_series_id_num_list = find_num_slices_list(final_test_df, final_test_df_unique_series_id_list)\n",
    "assert(len(final_test_df_unique_series_id_list)==len(final_test_df_unique_series_id_num_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Generator Parameters\n",
    "\"\"\"\n",
    "image_size = (512, 512)\n",
    "stack_size = 32\n",
    "overlap_size = 0\n",
    "batch_size = 1\n",
    "assert(overlap_size < stack_size)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Gen Object for whole test dataset\n",
    "\"\"\"\n",
    "\n",
    "final_test_df_gen_3D = VolDataGenerator3D(ct_dataframe = final_test_df,\n",
    "                               unique_id_list = final_test_df_unique_series_id_list,\n",
    "                               list_num_slices_list = final_test_df_unique_series_id_num_list,\n",
    "                               batch_size = batch_size,\n",
    "                               image_size = image_size,\n",
    "                               stack_size = stack_size,\n",
    "                               overlap_size = overlap_size)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data Gen Object for the Individual Scan\n",
    "\"\"\"\n",
    "x = 22              # Index of the CT scan you want to evaluate in the test set\n",
    "\n",
    "temp_id_gen_3D = VolDataGenerator3D(ct_dataframe = final_test_df,\n",
    "                               unique_id_list = final_test_df_unique_series_id_list[x:x+1],\n",
    "                               list_num_slices_list = final_test_df_unique_series_id_num_list[x:x+1],\n",
    "                               batch_size = batch_size,\n",
    "                               image_size = image_size,\n",
    "                               stack_size = stack_size,\n",
    "                               overlap_size = overlap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "V-net imported\n",
    "\"\"\"\n",
    "image_shape = (image_size[0], image_size[1], stack_size)\n",
    "group_size = 2\n",
    "f_root = 8\n",
    "filters = 4\n",
    "model_3D = VNet(image_shape=image_shape, n_in=1, n_out=1, \n",
    "        strides=1, padding='same', kernel_size=3,\n",
    "        groups=group_size, data_format='channels_first',\n",
    "        inter_filters=f_root, filters = filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the weight for the Model\"\"\"\n",
    "\n",
    "model_checkpoint_path = '/opt/bucketdata/Users/...'\n",
    "model_3D.load_weights(os.path.join(model_checkpoint_path, 'Weights', '....hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions for only one CT scan\n",
    "\"\"\"\n",
    "temp_id_pred_3D = model_3D.predict_generator(temp_id_gen_3D, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Predictions for the whole test dataset\n",
    "\"\"\"\n",
    "final_test_df_preds_3D = model_3D.predict_generator(final_test_df_gen_3D, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Side by side plotting of slice, label mask, and pred mask\n",
    "\"\"\"\n",
    "\n",
    "ImageSliceViewer3DMultipleColour(np.squeeze(temp_id_gen_3D[4][0]), np.squeeze(temp_id_gen_3D[4][1]), (np.squeeze(temp_id_pred_3D[4]>0.20)), cmap='gray', figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSITIVE PIXELS IN IMAGE:For temp ID INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making the true label volume for that scan\n",
    "\"\"\"\n",
    "\n",
    "temp_label_list = [(np.squeeze(temp_id_gen_3D[i][1])>0).astype(int) for i in range(len(temp_id_pred_3D))]\n",
    "temp_label_vol_3D = np.dstack((temp_label_list))\n",
    "temp_label_vol_3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Making the predicted masks volume for that scan\n",
    "\"\"\"\n",
    "\n",
    "temp_preds_list = [np.squeeze(temp_id_pred_3D[i]) for i in range(len(temp_id_pred_3D))]\n",
    "temp_pred_vol_3D = np.dstack((temp_preds_list))\n",
    "temp_pred_vol_3D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Counting the number of positive pixels in each slice OR area of mask of Prediced 3D Volume\n",
    "\"\"\"\n",
    "\n",
    "threshold = 0.20       #Thresholding value\n",
    "temp_pred_vol_3D = (temp_pred_vol_3D>threshold).astype(int)\n",
    "pred_list_of_ones_3D = []\n",
    "for pred in tqdm(range(temp_pred_vol_3D.shape[2])):\n",
    "    pred = temp_pred_vol_3D[:,:,pred]\n",
    "    counts_1_0 = Counter(pred.flatten())\n",
    "    pred_list_of_ones_3D.append(counts_1_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Counting the number of positive pixels in each slice OR area of mask of the True label mask volume\n",
    "\"\"\"\n",
    "\n",
    "label_list_of_ones_3D = []\n",
    "for label in tqdm(range(temp_label_vol_3D.shape[2])):\n",
    "    label = temp_label_vol_3D[:,:,label]\n",
    "    counts_1_0 = Counter(label.flatten())\n",
    "    label_list_of_ones_3D.append(counts_1_0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting the normalised size of the masks for predicted and label 3D Volume\n",
    "\"\"\"\n",
    "\n",
    "normalised_pred_list_of_ones_3D = [i/max(pred_list_of_ones_3D) for i in pred_list_of_ones_3D]\n",
    "plt.plot(normalised_pred_list_of_ones_3D)\n",
    "plt.show()\n",
    "normalised_label_list_of_ones_3D = [i/max(label_list_of_ones_3D) for i in label_list_of_ones_3D]\n",
    "plt.plot(normalised_label_list_of_ones_3D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DICE COEFF: POSITIVE SLICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(true,pred):\n",
    "    \"\"\"\"\n",
    "    Basiv Dice Score Function\n",
    "    \"\"\"\n",
    "    return (1-(distance.dice(true.ravel(),pred.ravel())))\n",
    "\n",
    "\n",
    "dice_scores_temp_list_3D=[]        #list of dice score of each slice in te CT Scan volume\n",
    "for i in tqdm(range(temp_pred_vol_3D.shape[2])):\n",
    "    score=dice_score(temp_label_vol_3D[:,:,i], temp_pred_vol_3D[:,:,i])\n",
    "    dice_scores_temp_list_3D.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Approach\n",
    "\"\"\"\n",
    "Remove nan values and 0 values from the dice score list\n",
    "\"\"\"\n",
    "\n",
    "dice_scores_temp_list_pos_only_3D = [element for element in dice_scores_temp_list_3D if element!=0]\n",
    "dice_scores_temp_list_pos_only_3D = [element for element in dice_scores_temp_list_pos_only_3D if not np.isnan(element)]\n",
    "mean(dice_scores_temp_list_pos_only_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd Approach\n",
    "\"\"\"\n",
    "Replace nan values with 1 (true negatives) and remove 0 values\n",
    "\"\"\"\n",
    "dice_scores_temp_list_pos_only_3D = []\n",
    "for i in dice_scores_temp_list_3D:\n",
    "    if np.isnan(i):\n",
    "        dice_scores_temp_list_pos_only_3D.append(1)\n",
    "    else:\n",
    "        dice_scores_temp_list_pos_only_3D.append(i)\n",
    "        \n",
    "dice_scores_temp_list_pos_only_3D = [element for element in dice_scores_temp_list_pos_only_3D if element!=0]\n",
    "mean(dice_scores_temp_list_pos_only_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Inference, everything in a LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gives us the index of CTs which are positive\n",
    "\"\"\"\n",
    "\n",
    "final_test_df_unique_series_id_list_only_pos = []\n",
    "for i in range(len(final_test_df_unique_id_list)):\n",
    "    id_1_df = (final_test_df.loc[final_test_df.unique_identifier==final_test_df_unique_id_list[i]]).reset_index(drop=True)\n",
    "    couer = Counter(id_1_df.true_label)\n",
    "    if couer[1]!=0:\n",
    "        final_test_df_unique_series_id_list_only_pos.append(i)\n",
    "final_test_df_unique_series_id_list_only_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#LOOP FOR ALL THE CT SCANS TOGETHER\n",
    "\"\"\"\"\n",
    "\n",
    "normalised_pred_list_of_ones_3D_LIST = []\n",
    "normalised_label_list_of_ones_3D_LIST = []\n",
    "\n",
    "nan_not1butremoved_dice_scores_temp_list_pos_only_3D_nan_removed_LIST = []\n",
    "nan_not1butremoved_dice_scores_temp_list_pos_only_3D_ZEROes_removed_LIST = []\n",
    "\n",
    "for i in (final_test_df_unique_series_id_list_only_pos):\n",
    "    temp_id_gen_3D = VolDataGenerator3D(ct_dataframe = final_test_df,\n",
    "                               unique_id_list = final_test_df_unique_series_id_list[i:i+1],\n",
    "                               list_num_slices_list = final_test_df_unique_series_id_num_list[i:i+1],\n",
    "                               batch_size = batch_size,\n",
    "                               image_size = image_size,\n",
    "                               stack_size = stack_size,\n",
    "                               overlap_size = overlap_size)\n",
    "    \n",
    "    temp_id_pred_3D = model_3D.predict_generator(temp_id_gen_3D, verbose=1)\n",
    "\n",
    "    print(\"#1*****\")\n",
    "    temp_label_list = [(np.squeeze(temp_id_gen_3D[i][1])>0).astype(int) for i in range(len(temp_id_pred_3D))]\n",
    "    temp_label_vol_3D = np.dstack((temp_label_list))\n",
    "    \n",
    "    print(\"#2*****\")\n",
    "    temp_preds_list = [np.squeeze(temp_id_pred_3D[i]) for i in range(len(temp_id_pred_3D))]\n",
    "    temp_pred_vol_3D = np.dstack((temp_preds_list))\n",
    "    \n",
    "    print(\"#3*****\")\n",
    "    assert(temp_label_vol_3D.shape == temp_pred_vol_3D.shape)\n",
    "    \n",
    "    print(\"#4*****\")\n",
    "    temp_pred_vol_3D = (temp_pred_vol_3D>0.20).astype(int)\n",
    "    pred_list_of_ones_3D = []\n",
    "    for pred in tqdm(range(temp_pred_vol_3D.shape[2])):\n",
    "        pred = temp_pred_vol_3D[:,:,pred]\n",
    "        counts_1_0 = Counter(pred.flatten())\n",
    "        pred_list_of_ones_3D.append(counts_1_0[1])\n",
    "        \n",
    "        \n",
    "    print(\"#5*****\")\n",
    "    label_list_of_ones_3D = []\n",
    "    for label in tqdm(range(temp_label_vol_3D.shape[2])):\n",
    "        label = temp_label_vol_3D[:,:,label]\n",
    "        counts_1_0 = Counter(label.flatten())\n",
    "        label_list_of_ones_3D.append(counts_1_0[1])\n",
    "        \n",
    "    print(\"#6*****\")\n",
    "    normalised_pred_list_of_ones_3D = [i/max(pred_list_of_ones_3D) for i in pred_list_of_ones_3D]\n",
    "\n",
    "    normalised_label_list_of_ones_3D = [i/max(label_list_of_ones_3D) for i in label_list_of_ones_3D]\n",
    "    \n",
    "    print(\"#7*****\")\n",
    "    \n",
    "    \n",
    "    normalised_pred_list_of_ones_3D_LIST.append(normalised_pred_list_of_ones_3D)\n",
    "    normalised_label_list_of_ones_3D_LIST.append(normalised_label_list_of_ones_3D)\n",
    "    \n",
    "    print(\"#8*****\")\n",
    "    def dice_score(true,pred):\n",
    "        return (1-(distance.dice(true.ravel(),pred.ravel())))\n",
    "\n",
    "    dice_scores_temp_list_3D=[]\n",
    "    for i in tqdm(range(temp_pred_vol_3D.shape[2])):\n",
    "        score=dice_score(temp_label_vol_3D[:,:,i], temp_pred_vol_3D[:,:,i])\n",
    "        dice_scores_temp_list_3D.append(score)\n",
    "        \n",
    "    print(\"#9*****\")\n",
    "    dice_scores_temp_list_pos_only_3D = []\n",
    "    for i in dice_scores_temp_list_3D:\n",
    "        if np.isnan(i):\n",
    "#             dice_scores_temp_list_pos_only_3D.append(1)\n",
    "            pass\n",
    "        else:\n",
    "            dice_scores_temp_list_pos_only_3D.append(i)\n",
    "\n",
    "    print(mean(dice_scores_temp_list_pos_only_3D))\n",
    "    nan_not1butremoved_dice_scores_temp_list_pos_only_3D_nan_removed_LIST.append(mean(dice_scores_temp_list_pos_only_3D))\n",
    "    \n",
    "    dice_scores_temp_list_pos_only_3D = [element for element in dice_scores_temp_list_pos_only_3D if element!=0]\n",
    "    \n",
    "    try:\n",
    "        if mean(dice_scores_temp_list_pos_only_3D)==1:\n",
    "            dice_scores_temp_list_pos_only_3D = [0]\n",
    "        print(mean(dice_scores_temp_list_pos_only_3D))\n",
    "    except:\n",
    "        print(\"StatisticsError\")\n",
    "        dice_scores_temp_list_pos_only_3D = [0]\n",
    "        \n",
    "    nan_not1butremoved_dice_scores_temp_list_pos_only_3D_ZEROes_removed_LIST.append(mean(dice_scores_temp_list_pos_only_3D))\n",
    "    \n",
    "    del(temp_label_vol_3D)\n",
    "    del(temp_pred_vol_3D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
